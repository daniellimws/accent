---
layout: post
type: note
title: 2.1 - Ignition
alias: v8
permalink: /notes/browser-pwn/ignition
---

## References
* [Understanding V8â€™s Bytecode [Franziska Hinkelmann]](https://medium.com/dailyjs/understanding-v8s-bytecode-317d46c94775)
* [V8 and How It Listens to You [Michael Stanton]](https://www.youtube.com/watch?v=u7zRSm8jzvA) ([slides](https://slides.com/ripsawridge/deck#/))
* [Ignition - an interpreter for V8 [Ross McIlroy]](https://www.youtube.com/watch?v=r5OWCtuKiAk&feature=youtu.be) ([slides](https://docs.google.com/presentation/d/1OqjVqRhtwlKeKfvMdX6HaCIu9wpZsrzqpIVIwQSuiXQ/edit#slide=id.gcd5fac7cb_3_11))
* [An Introduction to Speculative Optimization in V8 [Benedikt Meurer]](https://ponyfoo.com/articles/an-introduction-to-speculative-optimization-in-v8)
* [JavaScript engine fundamentals: Shapes and Inline Caches [Mathias Bynens]](https://mathiasbynens.be/notes/shapes-ics)
* [Explaining JavaScript VMs in JavaScript - Inline Caches [Vyacheslav Egorov]](https://mrale.ph/blog/2012/06/03/explaining-js-vms-in-js-inline-caches.html)

## 1. Compiler pipeline
### 1.1 How V8 Works
![](https://cdn-images-1.medium.com/max/2400/1*GuWInZljjvtDpdeT6O0emA.png)
<p align="center"><i>Source: <a href="https://medium.com/reloading/javascript-start-up-performance-69200f43b201">JavaScript Start-up Performance by Addy Osmani</a></i></p>

Take the following function for example,

```js
function add(x, y) {
    return x + y;
}

for (var i = 0; i < 1000000; ++i) {
    add(1, 2);
}

add("hello", "world");
```

The `add` function was called so many times that V8 marks it as "hot". So *Turbofan* will come in to optimize this function and produce machine code. Since `add` has only been called with **smi** arguments, *Turbofan* can produce machine code that only works for small integers.

Later, `add("hello", "world")` was called. Now the arguments are no longer **smis**, hence the assumption that the arguments are **smis** is invalid, and so V8 will deoptimize and fall back to bytecode.

### 1.2 Ignition - an interpreter for V8
Before Ignition existed, V8 was using *Full-codegen* as its baseline compiler (i.e. no optimizations), with two optimizing compilers, *Crankshaft* and *Turbofan*.

![][v8-old-pipeline]
<p align="center"><i>Source: <a href="https://docs.google.com/presentation/d/1OqjVqRhtwlKeKfvMdX6HaCIu9wpZsrzqpIVIwQSuiXQ/edit#slide=id.gcd5fac7cb_3_11">Slides by Ross McIlroy</a></i></p>

As seen the figure above, the source is parsed twice, the first time for the baseline compiler and another time for the optimizing compilers. Furthermore, both types of compilers produce machine code, which takes up a lot of space in memory. *Ignition* was designed to overcome this time and memory overhead.

![][v8-new-pipeline]
<p align="center"><i>Source: <a href="https://docs.google.com/presentation/d/1OqjVqRhtwlKeKfvMdX6HaCIu9wpZsrzqpIVIwQSuiXQ/edit#slide=id.gcd5fac7cb_3_11">Slides by Ross McIlroy</a></i></p>

In the new pipeline involving *Ignition*, as illustrated above, V8 only parses the source once, then stores it in the form of bytecode, which takes up less memory than machine code. **Hence lower memory usage**.

*Ignition* as an interpreter will execute the bytecode under normal circumstances. Although interpreted code are conventionally perceived to run slower than native, machine code, sometimes the time taken for V8 just to optimize and produce machine code is longer than that for executing bytecode. **Hence shorter execution time**.

When there is an opportunity for optimization, *Turbofan*, the sole optimizing compiler will perform optimizations on the bytecode according to assumptions made based on profiling information to produce machine code. Once these assumptions are invalid, V8 goes through a *deoptimization* phase, falling back to bytecode.
## 1. AST

## 2. Bytecode

## 3. Inline caches


[v8-old-pipeline]:{{site.baseurl}}/notes/browser-pwn/2-Execution/v8-old-pipeline.png
[v8-new-pipeline]:{{site.baseurl}}/notes/browser-pwn/2-Execution/v8-new-pipeline.png